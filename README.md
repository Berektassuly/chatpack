# ðŸ“¦ chatpack

> Compress chat exports from Telegram, WhatsApp, and Instagram into token-efficient CSV for LLMs.

Less tokens. Same conversation.

## âœ¨ Features

- **Token optimization** â€” Merges consecutive messages from the same sender, reducing token count by 30-50%
- **Multi-platform** â€” Supports Telegram, WhatsApp, and Instagram exports
- **Clean output** â€” Strips metadata (timestamps, IDs, reactions) leaving only sender and content
- **LLM-ready** â€” CSV format with semicolon delimiter, perfect for feeding into AI models
- **Fast** â€” Written in Rust for maximum performance

## ðŸ“Š Example

**Before** (62 messages):
```
[14:25] Alice: Hey
[14:25] Alice: How are you?
[14:26] Alice: Did you see the news?
[14:27] Bob: Hi! Yes I did
```

**After** (2 rows, 43.5% reduction):
```csv
Sender;Content
Alice;Hey
How are you?
Did you see the news?
Bob;Hi! Yes I did
```

## ðŸš€ Installation

### From source

```bash
git clone https://github.com/berektassuly/chatpack.git
cd chatpack
cargo build --release
```

Binary will be at `./target/release/chatpack`

### Using Cargo

```bash
cargo install --path .
```

## ðŸ“– Usage

```bash
chatpack <source> <input_file> [output_file]
```

### Examples

```bash
# Telegram JSON export
chatpack telegram result.json
chatpack tg chat.json output.csv

# WhatsApp TXT export
chatpack whatsapp _chat.txt
chatpack wa chat.txt messages.csv

# Instagram JSON export
chatpack instagram messages.json
chatpack ig inbox.json chat.csv
```

### Options

| Flag | Description |
|------|-------------|
| `-h, --help` | Show help message |
| `-v, --version` | Show version |

### Output format

- **File:** `optimized_chat.csv` (default)
- **Delimiter:** Semicolon (`;`)
- **Columns:** `Sender`, `Content`
- **Encoding:** UTF-8

## ðŸ“± Supported Sources

| Source | Format | Status | Export guide |
|--------|--------|--------|--------------|
| Telegram | JSON | âœ… Ready | Desktop â†’ Settings â†’ Export chat |
| WhatsApp | TXT | ðŸ”² Coming | Chat â†’ More â†’ Export chat |
| Instagram | JSON | ðŸ”² Coming | Settings â†’ Download your data |

## ðŸ—ï¸ Project Structure

```
chatpack/
â”œâ”€â”€ Cargo.toml
â””â”€â”€ src/
    â”œâ”€â”€ main.rs              # CLI entry point
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ mod.rs
    â”‚   â”œâ”€â”€ models.rs        # InternalMessage struct
    â”‚   â””â”€â”€ processor.rs     # Merge logic + CSV writer
    â””â”€â”€ parsers/
        â”œâ”€â”€ mod.rs           # ChatParser trait + factory
        â”œâ”€â”€ telegram.rs      # âœ… Implemented
        â”œâ”€â”€ whatsapp.rs      # ðŸ”² Stub
        â””â”€â”€ instagram.rs     # ðŸ”² Stub
```

## ðŸ”§ Adding a New Parser

1. Create `src/parsers/newsource.rs`:

```rust
use crate::core::InternalMessage;
use super::ChatParser;

pub struct NewSourceParser;

impl NewSourceParser {
    pub fn new() -> Self { Self }
}

impl ChatParser for NewSourceParser {
    fn name(&self) -> &'static str {
        "NewSource"
    }

    fn parse(&self, file_path: &str) -> Result<Vec<InternalMessage>, Box<dyn Error>> {
        // Your parsing logic here
        // Return Vec<InternalMessage { sender, content }>
    }
}
```

2. Register in `src/parsers/mod.rs`:

```rust
mod newsource;
pub use newsource::NewSourceParser;

// In ChatSource enum:
NewSource,

// In from_arg():
"newsource" | "ns" => Some(Self::NewSource),

// In create_parser():
ChatSource::NewSource => Box::new(NewSourceParser::new()),
```

3. Done! No changes needed in `main.rs` or `processor.rs`.

## ðŸ§ª Running Tests

```bash
cargo test
```

## ðŸ“ˆ Benchmarks

| Chat size | Messages | After merge | Reduction | Time |
|-----------|----------|-------------|-----------|------|
| Small | 62 | 35 | 43.5% | <1ms |
| Medium | 1,000 | ~600 | ~40% | ~5ms |
| Large | 10,000 | ~5,500 | ~45% | ~50ms |

## ðŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/discord-parser`)
3. Implement the `ChatParser` trait for your source
4. Add tests
5. Submit a pull request

## ðŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

## ðŸ™ Acknowledgments

- Built for the AI era, where every token counts
- Inspired by the need to analyze chat histories with LLMs without burning through context windows